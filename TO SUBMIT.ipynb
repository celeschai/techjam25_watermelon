{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4589a9e3",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2fd4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "777713bb-b282-468d-970e-04942240967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import gzip\n",
    "import json\n",
    "import io\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8347f1a",
   "metadata": {},
   "source": [
    "## Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58bb5a",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae010a1",
   "metadata": {},
   "source": [
    "First, we import in the data for google reviews in Vermont, USA, and convert it into a dataframe entitled `vt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d2aa71c-65b6-482b-b6a8-3e38afb8e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://mcauleylab.ucsd.edu/public_datasets/gdrive/googlelocal/review-Vermont_10.json.gz'\n",
    "\n",
    "response = requests.get(url, stream = True)\n",
    "response.raise_for_status() \n",
    "\n",
    "with gzip.GzipFile(fileobj = io.BytesIO(response.content), mode = 'rb') as gz_file:\n",
    "    data_list = [json.loads(line) for line in gz_file]\n",
    "\n",
    "vt = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa7cd6fc-8da6-41de-98e2-3ab8303f030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(324725, 8)\n",
      "Index(['user_id', 'name', 'time', 'rating', 'text', 'pics', 'resp', 'gmap_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(vt.shape) # 324725 observations and 8 columns.\n",
    "print(vt.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d922bb77-72e2-466a-a7cc-a4d554e69c18",
   "metadata": {},
   "source": [
    "Next, we import in the data for local businesses metadata in Vermont, USA, and convert it into a dataframe entitled `vt_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e151a00-4ca4-4bde-9b95-8a7c6f5b3ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_metadata = 'https://mcauleylab.ucsd.edu/public_datasets/gdrive/googlelocal/meta-Vermont.json.gz'\n",
    "\n",
    "response_metadata = requests.get(url_metadata, stream = True)\n",
    "response_metadata.raise_for_status() \n",
    "\n",
    "with gzip.GzipFile(fileobj = io.BytesIO(response_metadata.content), mode = 'rb') as gz_file:\n",
    "    data_list1 = [json.loads(line) for line in gz_file]\n",
    "\n",
    "vt_metadata = pd.DataFrame(data_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1824f28-8fd0-496a-8c2d-6bc1e8d31b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11291, 15)\n",
      "Index(['name', 'address', 'gmap_id', 'description', 'latitude', 'longitude',\n",
      "       'category', 'avg_rating', 'num_of_reviews', 'price', 'hours', 'MISC',\n",
      "       'state', 'relative_results', 'url'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(vt_metadata.shape) # 11291 observations and 15 columns\n",
    "print(vt_metadata.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71683f6e-2bce-4708-961c-fa73675ec170",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Next, we clean and prepare  the two datasets for analysis. We start with the reviews dataset before moving on to the business metadata dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeb993a",
   "metadata": {},
   "source": [
    "#### Reviews dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed24ef9-0d84-4199-8b77-6340413ee9bf",
   "metadata": {},
   "source": [
    "We'll perform the following steps on the reviews dataset:\n",
    "\n",
    "1. Drop the irrelevant `name` column to avoid redundancy as users can be identified by `user_id`\n",
    "2. Convert text in all columns to lower case\n",
    "3. Clean `text` by replacing multiple spaces with a single space\n",
    "4. Remove duplicate reviews based on user id, review text comment, business location, and time uploaded, to ensure each review is unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326e17de-8126-4d56-aea5-b76dddc552b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt = vt.drop('name', axis = 1) # drop 'name' column as it's not relevant to our analysis\n",
    "vt.columns = vt.columns.str.lower() # convert all strings to lower case\n",
    "vt['text'] = vt['text'].str.replace(r'\\s+', ' ', regex = True) # clean text \n",
    "vt = vt.drop_duplicates(subset = ['user_id', 'text', 'gmap_id', 'time']) # drop duplicate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf25292",
   "metadata": {},
   "source": [
    "Next, as the urls for the pictures in the `pics` column is presented in a nested dictionary, we write a function to collapse all urls into a single python list. We name the new column as `pics_collapsed` and drop the old `pics` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87d0f1eb-e7a9-4094-a959-2319b9e845c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_pics(pic_list):\n",
    "    if not pic_list:\n",
    "        return []  \n",
    "    urls = []\n",
    "    for pic_dict in pic_list:\n",
    "        urls.extend(pic_dict.get('url', []))\n",
    "    return urls\n",
    "\n",
    "vt['pics_collapsed'] = vt['pics'].apply(collapse_pics)\n",
    "vt = vt.drop('pics', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068541e",
   "metadata": {},
   "source": [
    "Similarly, we write a function to collapse business responses to reviews in the `resp` column, naming the new column as `resp_collapsed` and dropping the old `resp` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38e6667d-398f-4016-a926-987e18d079d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texts(resp_entry):\n",
    "    if isinstance(resp_entry, dict):\n",
    "        # single response dict\n",
    "        return resp_entry.get(\"text\", \"\")\n",
    "    elif isinstance(resp_entry, list):\n",
    "        # list of response dicts\n",
    "        return \" \".join([d.get(\"text\", \"\") for d in resp_entry if isinstance(d, dict)])\n",
    "    elif isinstance(resp_entry, str):\n",
    "        # fallback: extract with regex if it's a string\n",
    "        texts = re.findall(r'\"text\":\\s*\"([^\"]*)\"', resp_entry)\n",
    "        return \" \".join(texts)\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "vt[\"resp_collapsed\"] = vt[\"resp\"].apply(extract_texts)\n",
    "vt = vt.drop(\"resp\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9c1f6d",
   "metadata": {},
   "source": [
    "The first 3 observations of the reviews dataframe are as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dbb1ee4-c426-46e1-8c2f-9a52ded07cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 user_id           time  rating  \\\n",
      "0  118026874392842649478  1620085852324       5   \n",
      "1  101532740754036204131  1580309946474       5   \n",
      "2  115404122636203550540  1605195974445       5   \n",
      "\n",
      "                                                text  \\\n",
      "0      Always done right from wood stove to screens!   \n",
      "1  A great company to work with. Their sales and ...   \n",
      "2  Great place to do business with staff was grea...   \n",
      "\n",
      "                                 gmap_id pics_collapsed  \\\n",
      "0  0x89e02445cb9db457:0x37f42bff4edf7a43             []   \n",
      "1  0x89e02445cb9db457:0x37f42bff4edf7a43             []   \n",
      "2  0x89e02445cb9db457:0x37f42bff4edf7a43             []   \n",
      "\n",
      "                                      resp_collapsed  \n",
      "0  Good Evening, Rebecca! Thanks SO much for the ...  \n",
      "1  Good Afternoon, Peter - Really appreciate the ...  \n",
      "2  Hi Chad!\\n\\nThank you so much for the 5-Star r...  \n"
     ]
    }
   ],
   "source": [
    "print(vt.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2659188a",
   "metadata": {},
   "source": [
    "#### Metadata dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbce18aa",
   "metadata": {},
   "source": [
    "We'll perform the following steps on the reviews dataset:\n",
    "\n",
    "1. Drop the irrelevant columns that will not be needed for analysis\n",
    "2. Convert text in all columns to lower case\n",
    "3. Clean `description` and `category` columns by replacing multiple spaces with a single space\n",
    "4. Remove duplicate reviews based on business name and Google Maps id to ensure each observation is unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93279217-294d-4ffe-8670-a37f6576a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_metadata = vt_metadata.drop(['address', 'latitude', 'longitude', 'avg_rating', 'num_of_reviews', 'price', 'hours', 'MISC', 'state', 'relative_results'], axis = 1)\n",
    "vt_metadata.columns = vt_metadata.columns.str.lower() \n",
    "vt_metadata['description'] = vt_metadata['description'].str.replace(r'\\s+', ' ', regex = True)\n",
    "vt_metadata['category'] = vt_metadata['category'].str.replace(r'\\s+', ' ', regex = True)\n",
    "vt_metadata = vt_metadata.drop_duplicates(subset = ['name','gmap_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d04eb7",
   "metadata": {},
   "source": [
    "The first 3 observations of the metadata dataframe are as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a6df133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       name                                gmap_id  \\\n",
      "0               Royal Group  0x89e02445cb9db457:0x37f42bff4edf7a43   \n",
      "1  Foxglove Farm and Forest  0x4cb549e8877cf0d7:0xe8f003e6d73392ae   \n",
      "2              Carr's Gifts  0x4cb54a301f3518f7:0x39af4eda1efb9117   \n",
      "\n",
      "  description  category                                                url  \n",
      "0        None       NaN  https://www.google.com/maps/place//data=!4m2!3...  \n",
      "1        None       NaN  https://www.google.com/maps/place//data=!4m2!3...  \n",
      "2        None       NaN  https://www.google.com/maps/place//data=!4m2!3...  \n"
     ]
    }
   ],
   "source": [
    "print(vt_metadata.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "467fb5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_metadata.to_csv('vt_metadata.csv')\n",
    "vt.to_csv('vt.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c21119",
   "metadata": {},
   "source": [
    "### Data Scraping for Business Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162deef",
   "metadata": {},
   "source": [
    "Scraping Process ...\n",
    "- scrape our own data to fill in blanks for description\n",
    "- scrape our own data to fill in blanks for category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8afe86",
   "metadata": {},
   "source": [
    "### Merging Reviews and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860079d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1b127a",
   "metadata": {},
   "source": [
    "First, we import the newly scraped data into a dataframe named `name` and drop the index column added by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844acbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to rename these after section 2 ^ is filled\n",
    "# vt_metadata = pd.read_csv('2_vt_metadata_scraped.csv')\n",
    "# vt_metadata = vt_metadata.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5484fd1d",
   "metadata": {},
   "source": [
    "Next, we merge the reviews and metadata dataframes by common key `gmap_id`, save the merged dataframe as `vt_merged`. We drop the  drop the now irrelevant `gmap_id` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9596d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_merged = pd.merge(vt, vt_metadata, on = 'gmap_id', how = 'inner')\n",
    "vt_merged = vt_merged.drop('gmap_id', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6790182e",
   "metadata": {},
   "source": [
    "We insert new column called `review_id` such that each review has a unique identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2cbe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_merged['review_id'] = range(len(vt_merged)) \n",
    "id_column = vt_merged.pop('review_id')\n",
    "vt_merged.insert(0, 'review_id', id_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f24c4d7",
   "metadata": {},
   "source": [
    "### Manual Labelling of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15527c7",
   "metadata": {},
   "source": [
    "We add 7 new boolean columns:\n",
    "1. `is_image_ad` TRUE if image uploaded is labelled as advertisement\n",
    "2. `is_image_irrelevant` TRUE if image uploaded is labelled as irrelevant\n",
    "3. `is_text_ad` TRUE if text comment is labelled as advertisement\n",
    "4. `is_text_irrelevant` TRUE if text comment is labelled as irrelevant\n",
    "5. `is_text_rant` TRUE if text comment is labelled as rant from non-visitor\n",
    "6. `is_review_ad` TRUE if either image or text comment is labelled as advertisement \n",
    "7. `is_review_irrelevant` TRUE if either image or text comment is labelled as irrelevant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b710f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_merged['is_image_ad'] = None\n",
    "vt_merged['is_image_ad'] = vt_merged['is_image_ad'].astype(bool)\n",
    "\n",
    "vt_merged['is_image_irrelevant'] = None\n",
    "vt_merged['is_image_irrelevant'] = vt_merged['is_image_irrelevant'].astype(bool)\n",
    "\n",
    "vt_merged['is_text_ad'] = None\n",
    "vt_merged['is_text_ad'] = vt_merged['is_text_ad'].astype(bool)\n",
    "\n",
    "vt_merged['is_text_irrelevant'] = None\n",
    "vt_merged['is_text_irrelevant'] = vt_merged['is_text_irrelevant'].astype(bool)\n",
    "\n",
    "vt_merged['is_text_rant'] = None\n",
    "vt_merged['is_text_rant'] = vt_merged['is_text_rant'].astype(bool)\n",
    "\n",
    "vt_merged[\"is_review_ad\"] = vt_merged[\"is_text_ad\"] | vt_merged[\"is_image_ad\"]\n",
    "\n",
    "vt_merged['is_review_irrelevant'] = vt_merged[\"is_image_irrelevant\"] | vt_merged[\"is_text_irrelevant\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe352c7",
   "metadata": {},
   "source": [
    "Next, we add 2 columns for quality check of the review.\n",
    "1. `helpfulness`\n",
    "    - `not_helpful` (review was relevant but did not add information to the reader)\n",
    "    - `helpful` (review provided some helpful information to make decisions about the visit)\n",
    "    - `very_helpful` (review gave crucial or new information that can significantly impact visit decisions)\n",
    "\n",
    "2. `sensibility` TRUE if the numerical star rating corresponds to the sentiments present in text review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f1e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"not_helpful\", \"helpful\", \"very_helpful\"]\n",
    "vt_merged[\"helpfulness\"] = pd.Categorical(\n",
    "    values=[\"\"] * len(vt_merged), \n",
    "    categories = categories,\n",
    "    ordered = True\n",
    ")\n",
    "\n",
    "vt_merged['sensibility'] = None\n",
    "vt_merged['sensibility'] = vt_merged['sensibility'].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5316029f",
   "metadata": {},
   "source": [
    "The columns of the dataframe are as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1353e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vt_merged.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c03bbf3",
   "metadata": {},
   "source": [
    "### Filtering for Reviews Containing Text and/or Pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa9bd6",
   "metadata": {},
   "source": [
    "We assume that a numerical star rating alone does not provide sufficient ustification on why a review would violate any of the three policies. Hence, in this project we only focus on looking at the reviews containing text comments and/or pictures. This filters out around 45% of all reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e127401",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_rating_only = vt_merged[\n",
    "    vt_merged[\"text\"].isna() & (vt_merged[\"pics_collapsed\"] == \"[]\")\n",
    "]\n",
    "\n",
    "vt_merged = vt_merged.drop(vt_rating_only.index) # contains text and/or pic\n",
    "\n",
    "print(\"Rating-only shape:\", vt_rating_only.shape)\n",
    "print(\"With image or review shape:\", vt_with_image_or_review.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a080df",
   "metadata": {},
   "source": [
    "We save the final dataframe as `vt_merged.csv`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
