{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dcd2726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 410 unique values to urlpart2.txt\n",
      "Found 3822 values in b but not in a. Results saved to remainingurls.txt\n"
     ]
    }
   ],
   "source": [
    "# Extracting the list of URLs that are covered in this search.\n",
    "import pandas as pd\n",
    "\n",
    "input_file = \"dpart2.csv\"\n",
    "output_file = \"urlpart2.txt\"\n",
    "column_name = \"url\"   # <-- change this to your column name\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Drop NaNs, get unique values, convert to list\n",
    "unique_values = df[column_name].dropna().unique().tolist()\n",
    "\n",
    "# Write to text file, one per line\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for value in unique_values:\n",
    "        f.write(str(value) + \"\\n\")\n",
    "\n",
    "print(f\"Extracted {len(unique_values)} unique values to {output_file}\")\n",
    "\n",
    "# Define file paths\n",
    "file_a = \"urlpart2.txt\"\n",
    "file_b = \"remainingurls.txt\"\n",
    "file_c = \"remainingurls.txt\"\n",
    "\n",
    "# Read values from files into sets\n",
    "with open(file_a, \"r\", encoding=\"utf-8\") as f:\n",
    "    set_a = set(line.strip() for line in f if line.strip())\n",
    "\n",
    "with open(file_b, \"r\", encoding=\"utf-8\") as f:\n",
    "    set_b = set(line.strip() for line in f if line.strip())\n",
    "\n",
    "# Compute difference: values in b but not in a\n",
    "diff = sorted(set_b - set_a)\n",
    "\n",
    "# Write result to file c\n",
    "with open(file_c, \"w\", encoding=\"utf-8\") as f:\n",
    "    for value in diff:\n",
    "        f.write(value + \"\\n\")\n",
    "\n",
    "print(f\"Found {len(diff)} values in b but not in a. Results saved to {file_c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf5f055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge multiple category columns into a single column in a CSV file\n",
    "import csv\n",
    "\n",
    "input_file = \"C:\\\\Users\\\\angel\\\\2025\\\\Others\\\\TechJam\\\\Data\\\\just remaining categories.csv\"\n",
    "output_file = \"cpart2.csv\"\n",
    "\n",
    "# Define the category columns you want to merge\n",
    "category_columns = [f\"categories/{i}\" for i in range(11)]\n",
    "\n",
    "with open(input_file, mode=\"r\", newline='', encoding=\"utf-8\") as infile, \\\n",
    "     open(output_file, mode=\"w\", newline='', encoding=\"utf-8\") as outfile:\n",
    "\n",
    "    reader = csv.DictReader(infile)\n",
    "    \n",
    "    # Keep all other fields except the category ones\n",
    "    other_fields = [field for field in reader.fieldnames if field not in category_columns]\n",
    "    \n",
    "    # Output fields: all other fields + one merged 'categories' field\n",
    "    fieldnames = other_fields + ['category']\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        # Extract non-empty, trimmed category values\n",
    "        categories = [row[col].strip() for col in category_columns if row[col].strip()]\n",
    "        \n",
    "        # Build new row with original fields\n",
    "        new_row = {field: row[field] if row[field] != \"\" else \"\" for field in other_fields}\n",
    "\n",
    "        # Always stringify the list\n",
    "        new_row[\"category\"] = f\"{categories}\"\n",
    "\n",
    "        writer.writerow(new_row)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec5011c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename searchString column to url in a CSV file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dpart2.csv\")\n",
    "\n",
    "# Option 1: rename a specific column\n",
    "df = df.rename(columns={\"searchString\": \"url\"})\n",
    "\n",
    "df.to_csv(\"dpart2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5e5637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file saved as dpart2.csv\n"
     ]
    }
   ],
   "source": [
    "# Remove the prefix \"Direct Detail URL: \" from the url column using pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load your file\n",
    "df = pd.read_csv(\"dpart2.csv\")\n",
    "\n",
    "# Remove the prefix \"Direct Detail URL: \" from the url column\n",
    "df['url'] = df['url'].str.replace(r\"^Direct Detail URL:\\s*\", \"\", regex=True)\n",
    "\n",
    "# Save back to a new file\n",
    "df.to_csv(\"dpart2.csv\", index=False)\n",
    "\n",
    "print(\"Cleaned file saved as dpart2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f44279e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved as vermont_text_merged.csv\n"
     ]
    }
   ],
   "source": [
    "# Adding missing descriptions and categories to main reviews file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# File paths \n",
    "main_file = \"vermont_text_merged.csv\"  \n",
    "supp_file = \"dcpart1.csv\"  # the uploaded supplemental file\n",
    "output_file = \"vermont_text_merged.csv\"\n",
    "\n",
    "# Load both files\n",
    "main_df = pd.read_csv(main_file)\n",
    "supp_df = pd.read_csv(supp_file)\n",
    "\n",
    "# Ensure consistent column names (lowercase, strip spaces)\n",
    "main_df.columns = [col.strip().lower() for col in main_df.columns]\n",
    "supp_df.columns = [col.strip().lower() for col in supp_df.columns]\n",
    "\n",
    "# We assume both have at least these columns: url, description, categories\n",
    "for idx, row in supp_df.iterrows():\n",
    "    url = row['url']\n",
    "    \n",
    "    # Find matching rows in main file\n",
    "    matches = main_df['url'] == url\n",
    "    \n",
    "    if matches.any():\n",
    "        # Update description if main file missing\n",
    "        \n",
    "        if pd.notna(row['description']) and row['description'].strip() != \"\":\n",
    "            main_df.loc[matches & (main_df['description'].isna() | (main_df['description'].str.strip() == \"\")),\n",
    "                        'description'] = row['description']\n",
    "        \n",
    "        \"\"\"\n",
    "        # Update categories if main file missing\n",
    "        if pd.notna(row['category']) and row['category'].strip() != \"\":\n",
    "            main_df.loc[matches & (main_df['category'].isna() | (str(main_df['category']).strip() == \"\")),\n",
    "                        'category'] = row['category']\n",
    "        \"\"\"\n",
    "\n",
    "# Save the updated file\n",
    "main_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Updated file saved as {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
