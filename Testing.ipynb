{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ffead5-35ca-4911-8321-702ae394f423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    review_id                user_id           time  rating  \\\n",
      "15         15  113658698063006557094  1520354731256       5   \n",
      "16         16  103134655243955314411  1628737744108       5   \n",
      "17         17  101856865551768948430  1606162783440       1   \n",
      "\n",
      "                                                 text  \\\n",
      "15                                                NaN   \n",
      "16  Very honest and helpful. Glad I went there. I ...   \n",
      "17  I had them replace two broken studs on my righ...   \n",
      "\n",
      "                                       pics_collapsed  \\\n",
      "15                                                 []   \n",
      "16                                                 []   \n",
      "17  ['https://lh5.googleusercontent.com/p/AF1QipPQ...   \n",
      "\n",
      "                                       resp_collapsed          name  \\\n",
      "15                                                NaN  Carr's Gifts   \n",
      "16  Wow, Angela, we love positive feedback! Thank ...         Midas   \n",
      "17  Hi Henry our Customer Service Team would be ha...         Midas   \n",
      "\n",
      "   description  category                                                url  \\\n",
      "15         NaN       NaN  https://www.google.com/maps/place//data=!4m2!3...   \n",
      "16         NaN       NaN  https://www.google.com/maps/place//data=!4m2!3...   \n",
      "17         NaN       NaN  https://www.google.com/maps/place//data=!4m2!3...   \n",
      "\n",
      "    image_Keywords  is_image_ad  is_image_irrelevant  text_keywords  \\\n",
      "15             NaN          NaN                  NaN            NaN   \n",
      "16             NaN          NaN                  NaN            NaN   \n",
      "17             NaN          NaN                  NaN            NaN   \n",
      "\n",
      "    is_text_ad  is_text_irrelevant  is_text_rant  \n",
      "15         NaN                 NaN           NaN  \n",
      "16         NaN                 NaN           NaN  \n",
      "17         NaN                 NaN           NaN  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6de7bb367e4dfdad2809cb388cf14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6680072c49e04148a435e2c139331899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n",
      "/var/folders/sd/m0m5n5_52c7_yt7wl56_jyjm0000gn/T/ipykernel_19945/76455890.py:41: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  test_file.at[idx, \"is_image_ad\"] = \"\"\n",
      "/var/folders/sd/m0m5n5_52c7_yt7wl56_jyjm0000gn/T/ipykernel_19945/76455890.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  test_file.at[idx, \"image_keywords\"] = \"\"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'splitlines'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m response \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     71\u001b[0m answer, rationale \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitlines\u001b[49m():\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer:\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     74\u001b[0m         answer \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'splitlines'"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "test_file = pd.read_csv('vt_merged.csv').drop('Unnamed: 0', axis = 1).iloc[15:18]\n",
    "print(test_file)\n",
    "\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "login(token=hf_token)\n",
    "\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model_id = \"google/gemma-3-4b-it\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"image-text-to-text\",\n",
    "    model=model_id,\n",
    "    device=device,          \n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Testing ads + description\n",
    "\n",
    "advertisement_examples = [\n",
    "    \"Billboard with product name and price\",\n",
    "    \"Social media post promoting a sale\",\n",
    "    \"Banner showing a company logo with a slogan\",\n",
    "    \"Flyer with a discount coupon\"\n",
    "]\n",
    "\n",
    "for idx, row in test_file.iterrows():\n",
    "    image_list = ast.literal_eval(row['pics_collapsed'])  # convert string to list\n",
    "\n",
    "    if not image_list:  # skip empty lists\n",
    "        test_file.at[idx, \"is_image_ad\"] = \"\"\n",
    "        test_file.at[idx, \"image_keywords\"] = \"\"\n",
    "        continue\n",
    "\n",
    "    answers = []\n",
    "    descriptions = []\n",
    "\n",
    "    for image_url in image_list:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": (\n",
    "                        \"You are an AI assistant that classifies images as advertisements. \"\n",
    "                        \"Always respond in two clearly labeled sections: Answer, Description.\"\n",
    "                    )}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"url\": image_url},\n",
    "                    {\"type\": \"text\", \"text\": \"Is this image an advertisement?\"}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        output = pipe(messages, max_new_tokens=128)\n",
    "        response = output[0][\"generated_text\"]\n",
    "\n",
    "        answer, rationale = \"No\", \"\"\n",
    "        for line in response.splitlines():\n",
    "            if line.startswith(\"Answer:\"):\n",
    "                answer = line.split(\":\", 1)[1].strip()\n",
    "            elif line.startswith(\"Description:\"):\n",
    "                rationale = line.split(\":\", 1)[1].strip()\n",
    "\n",
    "        answers.append(answer)\n",
    "        descriptions.append(rationale)\n",
    "\n",
    "    # Final decision\n",
    "    final_answer = \"Yes\" if \"Yes\" in answers else \"No\"\n",
    "    test_file.at[idx, \"is_image_ad\"] = final_answer\n",
    "    test_file.at[idx, \"image_Keywords\"] = \" | \".join(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c15712-e56e-43d7-b65e-5a7bc303429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded4a63-8abd-4b15-a421-819c5112a6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
